{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd \nimport matplotlib.pyplot as plt \nimport sklearn as sk \nfrom mpl_toolkits.mplot3d import Axes3D\nimport os\nimport numpy as np",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = pd.read_csv('/kaggle/input/80-cereals/cereal.csv') #the first row are already variable names\ndf=pd.DataFrame(data)\ndf.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "header=df.columns #storing column names\nprint(header)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.nunique()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.info()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[df['carbo'] <0]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[df['potass']<0]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[df['sugars']<0]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[df['fiber']==14]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data=df.values\ndata=list(data)\n\n#removing the rowes that had -1 values:\ndata.pop(4) \ndata.pop(19)\ndata.pop(55)\n\n#removing the outlier row:\ndata.pop(3)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new=pd.DataFrame(data)\ndf_new.columns=header #We stored column names before.\ndf_new.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.describe()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new[df_new.duplicated()==True]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.isna().sum()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,10))\ndf.groupby('mfr')['rating'].mean().plot.bar(color='g')\nplt.title('Mean Ratings of Manufacturers')\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.type.value_counts()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.drop([\"name\",\"mfr\",\"type\",\"cups\"],axis='columns',inplace=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.shape",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "corr_mat=df_new.corr()\nmat=corr_mat.values\nplt.figure(figsize=(18,10))\nsn.heatmap(corr_mat, annot=True)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.drop([\"weight\"],axis='columns',inplace=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(7,7))\ndf.groupby('shelf')['shelf'].count().plot.pie(autopct = '%2.0f')\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.head() #checking out the dataframe",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#We visualize the relation between Sugar & Rating\ny_rating=df_new[\"rating\"]\nx_sugar=df_new[\"sugars\"]\nplt.figure(figsize=(7,7))\nsn.regplot(x=x_sugar,y=y_rating) #regression best fit line command\nplt.title('Sugar v. Cereal Rating')\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#We visualize the relation between Calories & Rating\nx_calories=df_new[\"calories\"]\nplt.figure(figsize=(7,7))\nsn.regplot(x=x_calories,y=y_rating)\nplt.title('Calories v. Cereal Rating')\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Let's check for relationship between fiber & ratings\nx_fiber=df_new[\"fiber\"]\nplt.figure(figsize=(7,7))\nsn.regplot(x=x_fiber,y=y_rating)\nplt.title('Fiber v. Cereal Rating')\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Checking the distribution of ratings\nplt.figure(figsize=(7,7))\nplt.hist(y_rating)\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Machine Learning Model \n#Regression",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dummies = pd.get_dummies(df_new['shelf'],prefix='shelf')\n\n#We have creative dummies for shelves:\n#shelf_1=> Shelf 1 Dummy\n#shelf_2=> Shelf 2 Dummy\n#shelf_3=> Shelf 3 Dummy\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new=pd.concat([df_new, dummies], axis=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.drop([\"shelf\"],axis='columns',inplace=True) #dropping original Shelf variable because now we have its dummies",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "cols = df_new.columns.tolist()\ncols.remove('rating')\ncols.append('rating')\nDF=df_new[cols]\nDF.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "DF.drop([\"shelf_3\"],axis='columns',inplace=True) #to solve dummy trap problem!\nDF.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "d=DF.values\nd=list(d)\n\n#creating y variable: ratings\ny=[]\nfor i in range(0,len(d)):\n  y.append(d[i][11])\ny=np.array(y)\n\n#creating x variables: All other variables except ratings\nx=[]\nfor i in range(0,len(d)):\n  x.append(d[i][:11])\nx=np.array(x)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x = sm.add_constant(x) #adding the constant/intercept to regression model\nmodel = sm.OLS(y, x).fit()\nmodel.summary()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "##x10 & x11 variable (shelf_1 and shelf_2, respectively) are insignifant at 95% confidence (since their t-stat < |1.96|). Hence, they do not impact cereal rating. We can drop them from our model.#",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#creating x variables again, this time not including dummies\nx=[]\nfor i in range(0,len(d)):\n  x.append(d[i][:9])\nx=np.array(x)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train = sm.add_constant(x_train) #adding the constant/intercept to regression model\nmodel = sm.OLS(y_train, x_train).fit()\nmodel.summary()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "##Now, all included variables are significant!\n#To visualize how each variable \"fits\" to predict the ratings:",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "sn.pairplot(DF, x_vars=['calories', 'protein', 'fat'], y_vars='rating', size=12, aspect=0.7, kind='reg')\nsn.pairplot(DF, x_vars=['sodium', 'fiber', 'carbo'], y_vars='rating', size=12, aspect=0.7, kind='reg')\nsn.pairplot(DF, x_vars=['sugars', 'potass', 'vitamins'], y_vars='rating', size=12, aspect=0.7, kind='reg')\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## How do we quantify the accuracy of our model? Ans: Mean Square Error.\nfrom sklearn.metrics import mean_squared_error\nx_test=sm.add_constant(x_test)\n#y_pred = model.get_prediction(x_test).summary_frame(alpha=0.05)\ny_pred=model.predict(x_test)\nprint(\"MSE: \",metrics.mean_absolute_error(y_test, y_pred))\nprint(\"MSA: \",metrics.mean_squared_error(y_test, y_pred))\nprint(\"RMSE: \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Mean Square Error is extremely small.\n#Our model is of the form:\n#Rating = 54.9 - 0.22 calories + 3.27 protein - 1.69 fat - 0.054 sodium + 3.44 fiber + 1.09 carbo - 0.724 sugars - 0.034 potass - 0.0512 * vitamins\n#For any given cereal, we can enter the amount of the mentioned ingredients and predict its ratings.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Since we won't be needing Shelf dummies anymore (they are not relevant), we can drop them:",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_new.drop([\"shelf_1\",\"shelf_2\",\"shelf_3\"],axis='columns',inplace=True)\ndf_new.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "##Groubby aggregations ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(cereal.csv, na_values= \"?\")\ndf",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## groupby sodium \ndf.groupby(['name'])(['sodium'])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## groupby type \ndf.groupby(['name'])(['type])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}